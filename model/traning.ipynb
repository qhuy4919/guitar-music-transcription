{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' A CNN to classify 6 fret-string positions\n",
    "    at the frame level during guitar performance\n",
    "'''\n",
    "\n",
    "from __future__ import print_function\n",
    "import keras\n",
    "import os\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten, Reshape, Activation\n",
    "from keras.layers import Conv2D, MaxPooling2D, Conv1D, Lambda\n",
    "from keras import backend as K\n",
    "from DataGenerator import DataGenerator\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime\n",
    "from Metrics import *\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "class TabCNN:\n",
    "    \n",
    "    def __init__(self, \n",
    "                 batch_size=128, \n",
    "                 epochs=30,\n",
    "                 con_win_size = 9,\n",
    "                 spec_repr=\"c\",\n",
    "                 data_path=\"../data/spec_repr/\",\n",
    "                 id_file=\"id.csv\",\n",
    "                 save_path=\"./model/saved/\"):   \n",
    "        \n",
    "        self.batch_size = batch_size\n",
    "        self.epochs = epochs\n",
    "        self.con_win_size = con_win_size\n",
    "        self.spec_repr = spec_repr\n",
    "        self.data_path = data_path\n",
    "        self.id_file = id_file\n",
    "        self.save_path = save_path\n",
    "        \n",
    "        self.load_IDs()\n",
    "        \n",
    "        self.save_folder = self.save_path + self.spec_repr + \" \" + datetime.datetime.now().strftime(\"%Y-%m-%d %H%M%S\") + \"/\"\n",
    "        if not os.path.exists(self.save_folder):\n",
    "            os.makedirs(self.save_folder)\n",
    "        self.log_file = self.save_folder + \"log.txt\"\n",
    "        \n",
    "        self.metrics = {}\n",
    "        self.metrics[\"pp\"] = []\n",
    "        self.metrics[\"pr\"] = []\n",
    "        self.metrics[\"pf\"] = []\n",
    "        self.metrics[\"tp\"] = []\n",
    "        self.metrics[\"tr\"] = []\n",
    "        self.metrics[\"tf\"] = []\n",
    "        self.metrics[\"tdr\"] = []\n",
    "        self.metrics[\"data\"] = [\"g0\",\"g1\",\"mean\",\"std dev\"]\n",
    "        \n",
    "        if self.spec_repr == \"c\":\n",
    "            self.input_shape = (192, self.con_win_size, 1)\n",
    "        elif self.spec_repr == \"m\":\n",
    "            self.input_shape = (128, self.con_win_size, 1)\n",
    "        elif self.spec_repr == \"cm\":\n",
    "            self.input_shape = (320, self.con_win_size, 1)\n",
    "        elif self.spec_repr == \"s\":\n",
    "            self.input_shape = (1025, self.con_win_size, 1)\n",
    "            \n",
    "        # these probably won't ever change\n",
    "        self.num_classes = 21\n",
    "        self.num_strings = 6\n",
    "\n",
    "    def load_IDs(self):\n",
    "        csv_file = self.data_path + self.id_file\n",
    "        self.list_IDs = list(pd.read_csv(csv_file, header=None)[0])\n",
    "        \n",
    "    def partition_data(self, data_split):\n",
    "        self.data_split = data_split\n",
    "        self.partition = {}\n",
    "        self.partition[\"training\"] = []\n",
    "        self.partition[\"validation\"] = []\n",
    "        for ID in self.list_IDs:\n",
    "            guitarist = int(ID.split(\"_\")[0])\n",
    "            if guitarist == data_split:\n",
    "                self.partition[\"validation\"].append(ID)\n",
    "            else:\n",
    "                self.partition[\"training\"].append(ID)\n",
    "                \n",
    "        self.training_generator = DataGenerator(self.partition['training'], \n",
    "                                                data_path=self.data_path, \n",
    "                                                batch_size=self.batch_size, \n",
    "                                                shuffle=True,\n",
    "                                                spec_repr=self.spec_repr, \n",
    "                                                con_win_size=self.con_win_size)\n",
    "        \n",
    "        self.validation_generator = DataGenerator(self.partition['validation'], \n",
    "                                                data_path=self.data_path, \n",
    "                                                batch_size=len(self.partition['validation']), \n",
    "                                                shuffle=False,\n",
    "                                                spec_repr=self.spec_repr, \n",
    "                                                con_win_size=self.con_win_size)\n",
    "        \n",
    "        self.split_folder = self.save_folder + str(self.data_split) + \"/\"\n",
    "        if not os.path.exists(self.split_folder):\n",
    "            os.makedirs(self.split_folder)\n",
    "                \n",
    "    def log_model(self):\n",
    "        with open(self.log_file,'w') as fh:\n",
    "            fh.write(\"\\nbatch_size: \" + str(self.batch_size))\n",
    "            fh.write(\"\\nepochs: \" + str(self.epochs))\n",
    "            fh.write(\"\\nspec_repr: \" + str(self.spec_repr))\n",
    "            fh.write(\"\\ndata_path: \" + str(self.data_path))\n",
    "            fh.write(\"\\ncon_win_size: \" + str(self.con_win_size))\n",
    "            fh.write(\"\\nid_file: \" + str(self.id_file) + \"\\n\")\n",
    "            self.model.summary(print_fn=lambda x: fh.write(x + '\\n'))\n",
    "       \n",
    "    def softmax_by_string(self, t):\n",
    "        sh = K.shape(t)\n",
    "        string_sm = []\n",
    "        for i in range(self.num_strings):\n",
    "            string_sm.append(K.expand_dims(K.softmax(t[:,i,:]), axis=1))\n",
    "        return K.concatenate(string_sm, axis=1)\n",
    "    \n",
    "    def catcross_by_string(self, target, output):\n",
    "        loss = 0\n",
    "        for i in range(self.num_strings):\n",
    "            loss += K.categorical_crossentropy(target[:,i,:], output[:,i,:])\n",
    "        return loss\n",
    "    \n",
    "    def avg_acc(self, y_true, y_pred):\n",
    "        return K.mean(K.equal(K.argmax(y_true, axis=-1), K.argmax(y_pred, axis=-1)))\n",
    "           \n",
    "    def build_model(self):\n",
    "        model = Sequential()\n",
    "        model.add(Conv2D(32, kernel_size=(3, 3),\n",
    "                             activation='relu',\n",
    "                             input_shape=self.input_shape))\n",
    "        model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "        model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "        model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "        model.add(Dropout(0.25))   \n",
    "        model.add(Flatten())\n",
    "        model.add(Dense(128, activation='relu'))\n",
    "        model.add(Dropout(0.5))\n",
    "        model.add(Dense(self.num_classes * self.num_strings)) # no activation\n",
    "        model.add(Reshape((self.num_strings, self.num_classes)))\n",
    "        model.add(Activation(self.softmax_by_string))\n",
    "\n",
    "        model.compile(loss=self.catcross_by_string,\n",
    "                      optimizer=tf.keras.optimizers.Adadelta(),\n",
    "                      metrics=[self.avg_acc])\n",
    "        \n",
    "        self.model = model\n",
    "\n",
    "    def train(self):\n",
    "        self.model.fit_generator(generator=self.training_generator,\n",
    "                    validation_data=None,\n",
    "                    epochs=self.epochs,\n",
    "                    verbose=1,\n",
    "                    use_multiprocessing=True,\n",
    "                    workers=9)\n",
    "        \n",
    "        \n",
    "    def save_weights(self):\n",
    "        # summarize history for accuracy\n",
    "        plt.plot(self.model.history['accuracy'])\n",
    "        plt.plot(self.model.history['val_accuracy'])\n",
    "        plt.title('model accuracy')\n",
    "        plt.ylabel('accuracy')\n",
    "        plt.xlabel('epoch')\n",
    "        plt.legend(['train', 'test'], loc='upper left')\n",
    "        plt.show()\n",
    "        # summarize history for loss\n",
    "        plt.plot(self.model.history['loss'])\n",
    "        plt.plot(self.model.history['val_loss'])\n",
    "        plt.title('model loss')\n",
    "        plt.ylabel('loss')\n",
    "        plt.xlabel('epoch')\n",
    "        plt.legend(['train', 'test'], loc='upper left')\n",
    "        plt.show()\n",
    "        self.model.save_weights(self.split_folder + \"weights.h5\")\n",
    "        \n",
    "    def test(self):\n",
    "        self.X_test, self.y_gt = self.validation_generator[0]\n",
    "        self.y_pred = self.model.predict(self.X_test)\n",
    "        \n",
    "    def save_predictions(self):\n",
    "        np.savez(self.split_folder + \"predictions.npz\", y_pred=self.y_pred, y_gt=self.y_gt)\n",
    "        \n",
    "    def evaluate(self):\n",
    "        self.metrics[\"pp\"].append(pitch_precision(self.y_pred, self.y_gt))\n",
    "        self.metrics[\"pr\"].append(pitch_recall(self.y_pred, self.y_gt))\n",
    "        self.metrics[\"pf\"].append(pitch_f_measure(self.y_pred, self.y_gt))\n",
    "        self.metrics[\"tp\"].append(tab_precision(self.y_pred, self.y_gt))\n",
    "        self.metrics[\"tr\"].append(tab_recall(self.y_pred, self.y_gt))\n",
    "        self.metrics[\"tf\"].append(tab_f_measure(self.y_pred, self.y_gt))\n",
    "        self.metrics[\"tdr\"].append(tab_disamb(self.y_pred, self.y_gt))\n",
    "        \n",
    "    def save_results_csv(self):\n",
    "        output = {}\n",
    "        for key in self.metrics.keys():\n",
    "            if key != \"data\":\n",
    "                vals = self.metrics[key]\n",
    "                mean = np.mean(vals)\n",
    "                std = np.std(vals)\n",
    "                output[key] = vals + [mean, std]\n",
    "        output[\"data\"] =  self.metrics[\"data\"]\n",
    "        df = pd.DataFrame.from_dict(output)\n",
    "        df.to_csv(self.save_folder + \"results.csv\") \n",
    "\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building model...\n",
      "training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_6111/3517225576.py:152: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  self.model.fit_generator(generator=self.training_generator,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "  65/3076 [..............................] - ETA: 32:03 - loss: 18.2471 - avg_acc: 0.0771"
     ]
    }
   ],
   "source": [
    "tabcnn = TabCNN()\n",
    "\n",
    "tabcnn.partition_data(1)\n",
    "print(\"building model...\")\n",
    "tabcnn.build_model()  \n",
    "print(\"training...\")\n",
    "tabcnn.train()\n",
    "tabcnn.save_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'loss': [11.932059288024902,\n",
       "  8.557585716247559,\n",
       "  8.10541820526123,\n",
       "  7.700138568878174,\n",
       "  7.3059611320495605,\n",
       "  6.956522464752197,\n",
       "  6.663934230804443,\n",
       "  6.4186482429504395],\n",
       " 'avg_acc': [0.5767424702644348,\n",
       "  0.7036663293838501,\n",
       "  0.7043523788452148,\n",
       "  0.7049041986465454,\n",
       "  0.7081124186515808,\n",
       "  0.7131471633911133,\n",
       "  0.7185296416282654,\n",
       "  0.7240813374519348]}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tabcnn.model.history.history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "15b51d8632b4e7920c6dc34c9c198195955906e1447a320d27454399a98e4d6b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
